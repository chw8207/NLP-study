{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1G8tK6-MsL0b0XQwMFdQ2a6PGGu3k2A0m",
      "authorship_tag": "ABX9TyP3Dn6cDLgQYCi2MBFPH7pz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chw8207/NLP-study/blob/main/%EC%98%90%ED%94%84_%EA%B0%90%EC%84%B1%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fBzSVYQMTrJ9"
      },
      "outputs": [],
      "source": [
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터셋"
      ],
      "metadata": {
        "id": "iXts6_qET533"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewDataset(Dataset) : \n",
        "  def __init__(self, review_df, vetorizer) : \n",
        "    \"\"\"\n",
        "        매개변수:\n",
        "            review_df (pandas.DataFrame): 데이터셋\n",
        "            vectorizer (ReviewVectorizer): ReviewVectorizer 객체\n",
        "    \"\"\"\n",
        "    self.review_df = review_df\n",
        "    self.vectorizer = vectorizer\n",
        "\n",
        "    self.train_df = self.review_df[self.review_df.split=='train']\n",
        "    self.train_size = len(self.train_df)\n",
        "\n",
        "    self.val_df = self.review_df[self.review_df.split=='val']\n",
        "    self.val_size = len(self.val_df)\n",
        "\n",
        "    self._lookup_dict = {'train':(self.train_df, self.train_size),\n",
        "                         'val':(self.val_df, self.val_size),\n",
        "                         'test':(self.test_df, self.test_size)}\n",
        "    self.set_split('train')\n",
        "\n",
        "  @classmethod  # 시작 메소드\n",
        "  def load_dataset_and_make_vectorizer(cls, review_csv) : \n",
        "    \"\"\" 데이터셋을 로드하고 새로운 ReviewVectorizer 객체를 만듭니다\n",
        "        \n",
        "        매개변수:\n",
        "            review_csv (str): 데이터셋의 위치\n",
        "        반환값:\n",
        "            ReviewDataset의 인스턴스\n",
        "    \"\"\"\n",
        "    review_df = pd.read_csv(review_csv)\n",
        "    return cls(review_df, ReviewVectorizer.from_dataframe(review_df))\n",
        "\n",
        "  @classmethod \n",
        "  def load_dataset_and_load_vectorizer(cls, review_csv, vectorizer_filepath) : \n",
        "    \"\"\" 데이터셋을 로드하고 새로운 ReviewVectorizer 객체를 만듭니다.\n",
        "        캐시된 ReviewVectorizer 객체를 재사용할 때 사용합니다.\n",
        "        \n",
        "        매개변수:\n",
        "            review_csv (str): 데이터셋의 위치\n",
        "            vectorizer_filepath (str): ReviewVectorizer 객체의 저장 위치\n",
        "        반환값:\n",
        "            ReviewDataset의 인스턴스\n",
        "    \"\"\"\n",
        "    review_df = pd.read_csv(review_csv)\n",
        "    vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "    return cls(review_df, vectorizer)\n",
        "\n",
        "  @staticmethod\n",
        "  def load_vectorizer_only(vectorizer_filepath) : \n",
        "    \"\"\" 파일에서 ReviewVectorizer 객체를 로드하는 정적 메서드\n",
        "        \n",
        "        매개변수:\n",
        "            vectorizer_filepath (str): 직렬화된 ReviewVectorizer 객체의 위치\n",
        "        반환값:\n",
        "            ReviewVectorizer의 인스턴스\n",
        "    \"\"\"\n",
        "    with open(vectorizer_filepath) as fp : \n",
        "      return ReviewVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "  def save_vectorizer(self, vectorizer_filepath) : \n",
        "    \"\"\" ReviewVectorizer 객체를 json 형태로 디스크에 저장합니다\n",
        "        \n",
        "        매개변수:\n",
        "            vectorizer_filepath (str): ReviewVectorizer 객체의 저장 위치\n",
        "    \"\"\"\n",
        "    with open(vectorizer_filepath, 'w') as fp :\n",
        "      json.dump(self._veotorizer._to_serializable(), fp)\n",
        "\n",
        "  def get_veotorizer(self) : \n",
        "    \"\"\" 벡터 변환 객체를 반환합니다 \"\"\"\n",
        "    return self._vectorizer\n",
        "\n",
        "  def set_split(self, split='train') : \n",
        "    \"\"\" 데이터프레임에 있는 열을 사용해 분할 세트를 선택합니다 \n",
        "        \n",
        "        매개변수:\n",
        "            split (str): \"train\", \"val\", \"test\" 중 하나\n",
        "    \"\"\"\n",
        "    self._target_split = split\n",
        "    self._target_df, self._target_size = self._lookup_dict[split]\n",
        "\n",
        "  def __len__(self) : \n",
        "    return self._target_size\n",
        "\n",
        "  def __getitem__(self, index) : \n",
        "    \"\"\" 파이토치 데이터셋의 주요 진입 메서드\n",
        "        \n",
        "        매개변수:\n",
        "            index (int): 데이터 포인트의 인덱스\n",
        "        반환값:\n",
        "            데이터 포인트의 특성(x_data)과 레이블(y_target)로 이루어진 딕셔너리\n",
        "    \"\"\"\n",
        "    row = self._target_df.iloc[index]\n",
        "    review_vector = self._vectorizer.vectorize(row.review)\n",
        "    rating_index = self._vectorizer.rating_vocab.lookuptoken(row.rating)\n",
        "\n",
        "    return {'X_data' : review_vector,\n",
        "            'y_target' : rating_index}\n",
        "\n",
        "  def get_num_batches(self, batch_size) : \n",
        "    \"\"\" 배치 크기가 주어지면 데이터셋으로 만들 수 있는 배치 개수를 반환합니다\n",
        "        \n",
        "        매개변수:\n",
        "            batch_size (int)\n",
        "        반환값:\n",
        "            배치 개수\n",
        "    \"\"\"\n",
        "    return len(self) // batch_size\n",
        "\n"
      ],
      "metadata": {
        "id": "6hKUeArKT5v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocabulary : 토큰을 정수로 매핑하기\n",
        "- UNK(unknown) : 훈련에서 본 적이 없는 토큰 처리 가능"
      ],
      "metadata": {
        "id": "OZBakxnBXjey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary(object) : \n",
        "  \"\"\" 매핑을 위해 텍스트를 처리하고 어휘 사전을 만드는 클래스 \"\"\"\n",
        "  def __init__(self, token_to_idx=None, add_unk=True, unk_token='<UNK>') : \n",
        "    \"\"\"\n",
        "        매개변수:\n",
        "            token_to_idx (dict): 기존 토큰-인덱스 매핑 딕셔너리\n",
        "            add_unk (bool): UNK 토큰을 추가할지 지정하는 플래그\n",
        "            unk_token (str): Vocabulary에 추가할 UNK 토큰\n",
        "    \"\"\"\n",
        "    if token_to_idx is None : \n",
        "      token_to_idx = {}\n",
        "    self._token_to_idx = token_to_idx"
      ],
      "metadata": {
        "id": "Y7ZW1umnXjRi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}